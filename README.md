
# Beyond Commercial APIs: Hosting Open LLMs for Your Needs

This repository contains the slides (PDF format) for the MICAI 2025 tutorial:

> **Beyond Commercial APIs: Hosting Open LLMs for Your Needs**

---

## ğŸ¯ Overview

This tutorial explores practical methods to **self-host, optimize, and integrate open Large Language Models (LLMs)** beyond commercial APIs.  
It covers a complete workflow â€” from hardware setup and backend serving to front-end integration and best practices.

---

## ğŸ§© Topics Covered

- Open LLM Landscape and terminology  
- Model formats, quantization, and efficiency tricks  
- Serving backends: vLLM, Ollama, LM Studio, and Open WebUI  
- Hardware & optimization strategies  
- Front-end integration and APIs  
- Hands-on workflows  
- Best practices and current trends

---

## ğŸ“¦ Contents

- `slides/` â†’ PDF version of the presentation  
---

## ğŸ§‘â€ğŸ’» Author

**Cesar Torres**  
PhD Candidate, TECNM/Tijuana Institute of Technology  
TECNM / Tijuana Institute of Technology
Thermo Fisher Scientific



---

## ğŸ“ License

This repository is shared for educational and research purposes.  
Â© 2025 Cesar Torres. All rights reserved.
